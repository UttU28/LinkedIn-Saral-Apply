CHROME_DRIVER_PATH=C:\\chromeDriver\\chromedriver.exe
CHROME_APP_PATH=C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe

# Scraping Chrome Data Directory (Temporary account for scraping, so banning of main account is prevented)
SCRAPING_CHROME_DIR=C:\\Users\\antonio\\Desktop\\Saral-Job-Apply\\chromeData\\irangarick
SCRAPING_PORT=9003

# Applying Chrome Data Directory (Main account for applying)
APPLYING_CHROME_DIR=C:\\Users\\antonio\\Desktop\\Saral-Job-Apply\\chromeData\\notirangarick
APPLYING_PORT=9005

# Database URL
DATABASE_URL=mysql://username:password@host:port/database_name

# LinkedIn Questions JSON file path (Merging with a different Application that automatically applies to jobs for Dice and Easy Apply in LinkedIn)
QUESTIONS_JSON=/home/robada/Desktop/Saral-Job-Apply/data/linkedinQuestions.json
DATA_DIR=C:\\Users\\antonio\\Desktop\\Saral-Job-Apply\\data



# Current Directory Structure
# Saral-Job-Apply/
# ├── app.py                    # FastAPI backend server
# ├── linkedInScraping.py       # LinkedIn scraping script
# ├── diceScraping.py          # Dice scraping script
# ├── requirements.txt         # Python dependencies
# ├── .env                     # Environment variables
# ├── .gitignore              # Git ignore file
# ├── utils/
# ├── services/
# ├── data/                    # Data directory for JSON files
#     └── linkedinQuestions.json
#     └── rawData.json